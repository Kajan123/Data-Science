{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9QT9Q5zMeuj"
      },
      "source": [
        "This is the beginning of the notebook.\n",
        "\n",
        "##ADM4142-A Fundamentals of Data science <br>\n",
        "The goal of this notebook is to retrieve and stage the source datasets into the format used in the dimensional model for analysis.\n",
        "\n",
        "This notebook generates the Economy_dimension of the weather/tourism/economy data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N08cmn-7IMoA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRIMVsxdMdAe",
        "outputId": "9d62838b-7a53-4bc3-d81f-a037931dac7e"
      },
      "outputs": [],
      "source": [
        "# Define the URL for the dataset\n",
        "dataset_url = 'https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/data/24100043_monthlyProvincial_tourists.csv'\n",
        "\n",
        "# Load the dataset\n",
        "tourism_data = pd.read_csv(dataset_url)\n",
        "\n",
        "# Remove apostrophes from all cells\n",
        "tourism_data = tourism_data.replace({\"\\\"\": \"\"}, regex=True)\n",
        "\n",
        "#tourism_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "2ktryYGrMvBg",
        "outputId": "b2823341-081e-4099-c53f-78c4397949b8"
      },
      "outputs": [],
      "source": [
        "#tourism_data.head()\n",
        "tourism_data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l9DCbNuw7i0"
      },
      "source": [
        "Now that we've imported the dataset, we need to transform it into the format that includes only the original columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "gHGNh34ySxBB",
        "outputId": "6308264c-58dc-40be-c1fd-3a6489fa63e9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Section 4: Filter rows by date\n",
        "start_date = '1990-01'\n",
        "end_date = '2023-12'\n",
        "tourism_data['REF_DATE'] = pd.to_datetime(tourism_data['REF_DATE'])\n",
        "tourism_data = tourism_data[(tourism_data['REF_DATE'] >= start_date) & (tourism_data['REF_DATE'] <= end_date)]\n",
        "\n",
        "# Section 5: Filter rows by GEO column\n",
        "valid_geo = ['Canada', 'Alberta', 'British Columbia', 'Ontario', 'Quebec']\n",
        "tourism_data = tourism_data[tourism_data['GEO'].isin(valid_geo)]\n",
        "#tourism_data = tourism_data[tourism_data['Seasonal adjustment'] == 'Unadjusted']\n",
        "\n",
        "tourism_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvlpFrlMLbpi",
        "outputId": "d05fa4cb-4c47-4d5e-b933-b06c1ba5bce3"
      },
      "outputs": [],
      "source": [
        "# Section 6: Prepare columns for keys (to be mapped later)\n",
        "tourism_data['Date_key'] = \"\"\n",
        "tourism_data['Weather_key'] = \"\"\n",
        "tourism_data['Location_key'] = \"\"\n",
        "tourism_data['Economy_key'] = \"\"\n",
        "\n",
        "# Section 7: Adjust columns based on Traveller characteristics\n",
        "tourism_data['Total non-resident tourists'] = tourism_data.loc[tourism_data['Traveller characteristics'] == 'Total non resident tourists', 'VALUE']\n",
        "tourism_data['United states tourists'] = tourism_data.loc[tourism_data['Traveller characteristics'] == 'United States tourists', 'VALUE']\n",
        "tourism_data['Non-US foreign tourists'] = tourism_data.loc[tourism_data['Traveller characteristics'] == 'Tourists from countries other than United States', 'VALUE']\n",
        "tourism_data['Canadian tourists returning from U.S.'] = tourism_data.loc[tourism_data['Traveller characteristics'] == 'Canadian tourists returning from United States', 'VALUE']\n",
        "tourism_data['Canadian tourists returning from abroad'] = tourism_data.loc[tourism_data['Traveller characteristics'] == 'Canadian tourists returning from countries other than United States', 'VALUE']\n",
        "tourism_data['Seasonally adjusted'] = tourism_data['Seasonal adjustment']\n",
        "\n",
        "\n",
        "\n",
        "# Section 9: Merge entries based on matching GEO and REF_DATE values\n",
        "tourism_data = tourism_data.groupby(['REF_DATE', 'GEO', 'Seasonal adjustment'], as_index=False).agg({\n",
        "    'Total non-resident tourists': 'sum',\n",
        "    'United states tourists': 'sum',\n",
        "    'Non-US foreign tourists': 'sum',\n",
        "    'Canadian tourists returning from U.S.': 'sum',\n",
        "    'Canadian tourists returning from abroad': 'sum',\n",
        "    #'Seasonally adjusted': 'first',  # Since it's unadjusted, all values should be the same\n",
        "})\n",
        "\n",
        "# Section 8: Select entries with \"Seasonal adjustment\" value \"Unadjusted\"\n",
        "unadjusted_data = tourism_data[tourism_data['Seasonal adjustment'] == 'Unadjusted']\n",
        "\n",
        "## to be used later\n",
        "adjusted_data = tourism_data.copy()\n",
        "adjusted_data = adjusted_data[tourism_data['Seasonal adjustment'] == 'Seasonally adjusted']\n",
        "##\n",
        "\n",
        "# make a copy to perform manipulations\n",
        "merged_data = unadjusted_data\n",
        "\n",
        "# Section 10: Calculate \"Total non-resident tourists\"\n",
        "merged_data['Total non-resident tourists'] = merged_data['United states tourists'] + merged_data['Non-US foreign tourists']\n",
        "\n",
        "# Section 10: Fill missing values for other attributes\n",
        "merged_data['Seasonal adjustment'].fillna(\"\", inplace=True)\n",
        "merged_data['Date_key'] = \"\"\n",
        "merged_data['Weather_key'] = \"\"\n",
        "merged_data['Location_key'] = \"\"\n",
        "merged_data['Economy_key'] = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "AKMZRyGaLbfz",
        "outputId": "34eaade5-67e2-45d8-cd4d-1a02bd1b05fd"
      },
      "outputs": [],
      "source": [
        "merged_data.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaVK2vEiWisY"
      },
      "source": [
        "Now, add the date dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MOGnVfZWiTp"
      },
      "outputs": [],
      "source": [
        "# Section 12: Load date dimension data\n",
        "date_dimension_url = \"https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/dimension/date.csv\"\n",
        "date_dimension = pd.read_csv(date_dimension_url)\n",
        "date_dimension['date_iso'] = pd.to_datetime(date_dimension['date_iso'])\n",
        "\n",
        "# Section 13: Merge with date dimension based on REF_DATE and date_iso\n",
        "merged_data = pd.merge(merged_data, date_dimension, left_on='REF_DATE', right_on='date_iso', how='left')\n",
        "\n",
        "# Section 14: Fill Date_key column with mapped values\n",
        "merged_data['Date_key'] = merged_data['Date_key_y']\n",
        "\n",
        "# Section 15: Drop unnecessary columns\n",
        "merged_data.drop(columns=['Date_key_x', 'Date_key_y', 'date_iso', 'day_of_week'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EiwUyyScJ16",
        "outputId": "0032499e-eae4-4409-cd92-e4665436d1a7"
      },
      "outputs": [],
      "source": [
        "# Count the number of missing values in the Date_key column\n",
        "missing_date_keys = merged_data['Date_key'].isna().sum()\n",
        "print(\"Number of missing values in the Date_key column:\", missing_date_keys)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSIytT8YZAs-"
      },
      "source": [
        "Now, add the location dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1eMlQBhDhMNT",
        "outputId": "8970eca7-95d6-4013-b85f-9c4c5d1db213"
      },
      "outputs": [],
      "source": [
        "# Section 17: Load location dimension data\n",
        "location_dimension_url = \"https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/dimension/location.csv\"\n",
        "location_dimension = pd.read_csv(location_dimension_url)\n",
        "#location_dimension = pd.merge(location_dimension, pd dimension)\n",
        "# Merge with location dimension based on Date_key\n",
        "location_dimension = pd.merge(location_dimension, date_dimension[['Date_key', 'year']], on='Date_key', how='left')\n",
        "#location_dimension['Date_key']\n",
        "\n",
        "# Section 24: Fill Economy_key column with mapped values\n",
        "#location_dimension['Date_key'] = location_dimension['Date_key_y']\n",
        "\n",
        "location_dimension.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLINHNXGZEAq"
      },
      "outputs": [],
      "source": [
        "# Section 18: Merge with location dimension based on Date_key and GEO\n",
        "merged_data = pd.merge(merged_data, location_dimension, left_on=['year', 'GEO'], right_on=['year', 'location'], how='left')\n",
        "\n",
        "# Section 19: Fill Location_key column with mapped values\n",
        "merged_data['Location_key'] = merged_data['Location_key_y']\n",
        "merged_data['Date_key'] = merged_data['Date_key_y']\n",
        "\n",
        "# Section 20: Drop unnecessary columns\n",
        "merged_data.drop(columns=['Location_key_x', 'Location_key_y', 'Date_key_x', 'Date_key_y', 'location', 'population'], inplace=True)\n",
        "\n",
        "# Section 21: Save the merged data as \"tourism_fact_table.csv\"\n",
        "#merged_data.to_csv(\"tourism_fact_table.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuzQjTQdcAga",
        "outputId": "71702f71-d877-4b36-c6e9-da941450c925"
      },
      "outputs": [],
      "source": [
        "# Count the number of missing values in the Location_key column\n",
        "missing_location_keys = merged_data['Location_key'].isna().sum()\n",
        "print(\"Number of missing values in the Location_key column:\", missing_location_keys)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "sMP7owjqcjhD",
        "outputId": "b52fe253-1048-4dad-a4a6-d3d7cf5ff4e2"
      },
      "outputs": [],
      "source": [
        "# Check the 10 entries starting from the 200th entry\n",
        "#print(merged_data.iloc[100:200])\n",
        "\n",
        "merged_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tYjLPUOZdVg"
      },
      "source": [
        "Now, add the economy dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNtjwQo0mPb7"
      },
      "outputs": [],
      "source": [
        "# Section 22: Load economy dimension data\n",
        "economy_dimension_url = \"https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/dimension/economy.csv\"\n",
        "#economy_dimension = pd.read_csv(economy_dimension_url)\n",
        "economy_dimension = pd.read_csv(economy_dimension_url, usecols=['Date_key', 'Location_key', 'Economy_key'])\n",
        "# Merge with date dimension based on Date_key to get year\n",
        "economy_dimension = pd.merge(economy_dimension, date_dimension[['Date_key', 'year']], on='Date_key', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2dQo-7paRXr"
      },
      "outputs": [],
      "source": [
        "# Section 23: Merge with economy dimension based on Date_key and Location_key\n",
        "temp_merged_data = pd.merge(merged_data, economy_dimension, on=['year', 'Location_key'], how='left')\n",
        "\n",
        "# Section 19: Fill Location_key column with mapped values\n",
        "merged_data['Economy_key'] = temp_merged_data['Economy_key_y']\n",
        "#merged_data['Date_key'] = merged_data['Date_key_y']\n",
        "\n",
        "# Section 24: Fill Economy_key column with mapped values\n",
        "#merged_data['Economy_key'] = temp_merged_data['Economy_key_y']\n",
        "\n",
        "# Section 25: Drop unnecessary columns\n",
        "#merged_data.drop(columns=['Economy_key_x', 'Economy_key_y', 'Date_key_x', 'Date_key_y'], inplace=True)\n",
        "\n",
        "# Section 26: Save the merged data as \"tourism_fact_table.csv\"\n",
        "#merged_data.to_csv(\"tourism_fact_table.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "7IX4NFDmizF7",
        "outputId": "10f670ba-7995-46a5-e77b-c84920915649"
      },
      "outputs": [],
      "source": [
        "merged_data.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eicjpc8XzQ8K",
        "outputId": "75de400d-8099-4f80-e3aa-381822131c72"
      },
      "outputs": [],
      "source": [
        "# Count the number of missing values in the Location_key column\n",
        "missing_economy_keys = merged_data['Economy_key'].isna().sum()\n",
        "print(\"Number of missing values in the Economy_key column:\", missing_economy_keys)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCK3JQYxu1lD"
      },
      "source": [
        "Finally, add the keys from Weather dimension. There are multiple Weather_keys corresponding to different cities from the same province when merging using Location_key and Date_key. These are combined into a single cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZGz4YZYu1Fz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Step 1: Load the weather dimension data\n",
        "weather_dimension_url = \"https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/dimension/weather_final.csv\"\n",
        "weather_dimension = pd.read_csv(weather_dimension_url, usecols=['Date_key', 'Location_key', 'Weather_key'])\n",
        "\n",
        "# Step 2: Preprocess the Weather Data\n",
        "# Aggregate Weather_key for each combination of Location_key and Date_key into a list, then convert to a JSON string\n",
        "weather_aggregated = weather_dimension.groupby(['Date_key', 'Location_key']).agg(\n",
        "    Weather_keys=('Weather_key', lambda x: json.dumps(list(x)))  # Convert the list of Weather_keys to JSON string\n",
        ").reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1k6doemgwBc6",
        "outputId": "3f6c5d31-89cb-4fb1-fb4d-551458e63d1f"
      },
      "outputs": [],
      "source": [
        "weather_aggregated.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-Iiwm4vv9fm"
      },
      "outputs": [],
      "source": [
        "# Step 3: Merge with the Main Data\n",
        "merged_data_with_weather = pd.merge(merged_data, weather_aggregated, on=['Location_key', 'Date_key'], how='left')\n",
        "merged_data['Weather_key'] = merged_data_with_weather['Weather_keys']\n",
        "\n",
        "# If needed, replace NaN values in Weather_keys with a default value, e.g., an empty list as a JSON string\n",
        "#merged_data['Weather_key'].fillna(json.dumps([]), inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "0JqfODUCwJvD",
        "outputId": "76045fd7-53dc-4a8c-9bad-7212daa7b0a8"
      },
      "outputs": [],
      "source": [
        "merged_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klK8DK8Lzam-",
        "outputId": "d5ff5672-bb0b-4841-fd5d-2ea16bd9fa72"
      },
      "outputs": [],
      "source": [
        "# Count the number of missing values in the Location_key column\n",
        "missing_weather_keys = merged_data['Weather_key'].isna().sum()\n",
        "print(\"Number of missing values in the Weather_key column:\", missing_weather_keys)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BanNkXoWxjpS"
      },
      "source": [
        "Completed. Note that There are no associated weather keys for rows whose location is \"Canada\", since there is no associated weather data included for the entire country.\n",
        "\n",
        "Now we need to perform the same procedure for the seasonally adjusted data, and concatenate the two sets into one final dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQxMovGZyrCp"
      },
      "outputs": [],
      "source": [
        "#merged_data_with_weather.head()\n",
        "final_data_unadjusted = merged_data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CfsqH9J2EYu"
      },
      "outputs": [],
      "source": [
        "# make a copy to perform manipulations\n",
        "merged_data = adjusted_data\n",
        "\n",
        "# Section 10: Calculate \"Total non-resident tourists\"\n",
        "merged_data['Total non-resident tourists'] = merged_data['United states tourists'] + merged_data['Non-US foreign tourists']\n",
        "\n",
        "# Section 10: Fill missing values for other attributes\n",
        "merged_data['Seasonal adjustment'].fillna(\"\", inplace=True)\n",
        "merged_data['Date_key'] = \"\"\n",
        "merged_data['Weather_key'] = \"\"\n",
        "merged_data['Location_key'] = \"\"\n",
        "merged_data['Economy_key'] = \"\"\n",
        "\n",
        "### Date dimension\n",
        "# Section 12: Load date dimension data\n",
        "\n",
        "# Section 13: Merge with date dimension based on REF_DATE and date_iso\n",
        "merged_data = pd.merge(merged_data, date_dimension, left_on='REF_DATE', right_on='date_iso', how='left')\n",
        "\n",
        "# Section 14: Fill Date_key column with mapped values\n",
        "merged_data['Date_key'] = merged_data['Date_key_y']\n",
        "\n",
        "# Section 15: Drop unnecessary columns\n",
        "merged_data.drop(columns=['Date_key_x', 'Date_key_y', 'date_iso', 'day_of_week'], inplace=True)\n",
        "\n",
        "### Location\n",
        "# Section 18: Merge with location dimension based on Date_key and GEO\n",
        "merged_data = pd.merge(merged_data, location_dimension, left_on=['year', 'GEO'], right_on=['year', 'location'], how='left')\n",
        "\n",
        "# Section 19: Fill Location_key column with mapped values\n",
        "merged_data['Location_key'] = merged_data['Location_key_y']\n",
        "merged_data['Date_key'] = merged_data['Date_key_y']\n",
        "\n",
        "# Section 20: Drop unnecessary columns\n",
        "merged_data.drop(columns=['Location_key_x', 'Location_key_y', 'Date_key_x', 'Date_key_y', 'location', 'population'], inplace=True)\n",
        "\n",
        "### Economy dimension\n",
        "merged_data['Location_key'] = merged_data['Location_key'].astype('int64')\n",
        "\n",
        "# Section 23: Merge with economy dimension based on Date_key and Location_key\n",
        "temp_merged_data_2 = pd.merge(merged_data, economy_dimension, on=['year', 'Location_key'], how='left')\n",
        "\n",
        "# Section 19: Fill Location_key column with mapped values\n",
        "merged_data['Economy_key'] = temp_merged_data_2['Economy_key_y']\n",
        "\n",
        "### Weather dimension\n",
        "# Step 3: Merge with the Main Data\n",
        "merged_data_with_weather_2 = pd.merge(merged_data, weather_aggregated, on=['Location_key', 'Date_key'], how='left')\n",
        "merged_data['Weather_key'] = merged_data_with_weather_2['Weather_keys']\n",
        "\n",
        "# If needed, replace NaN values in Weather_keys with a default value, e.g., an empty list as a JSON string\n",
        "#merged_data['Weather_key'].fillna(json.dumps([]), inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "5ihN1qt40tR8",
        "outputId": "aa1e8805-4fdc-4c5a-ff9f-5ec6b75bb0b3"
      },
      "outputs": [],
      "source": [
        "merged_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-FW1NnV8LvS"
      },
      "outputs": [],
      "source": [
        "final_data_adjusted = merged_data\n",
        "\n",
        "combined_data = pd.concat([final_data_unadjusted, final_data_adjusted], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "8kZyTHpZ8S7_",
        "outputId": "bd8ade09-64c9-4d0d-ad94-086c3b5f90f0"
      },
      "outputs": [],
      "source": [
        "combined_data.tail(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM5Dko1g8sap"
      },
      "source": [
        "Combine, sort, and organize attributes and rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU4HUl9F8r-l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Final selection and sorting of the columns\n",
        "final_data = combined_data[['Date_key', 'Weather_key', 'Location_key', 'Economy_key',\n",
        "                                          'Total non-resident tourists', 'United states tourists',\n",
        "                                          'Non-US foreign tourists', 'Canadian tourists returning from U.S.',\n",
        "                                          'Canadian tourists returning from abroad', 'Seasonal adjustment']].copy()\n",
        "\n",
        "final_data['Seasonal adjustment'] = final_data['Seasonal adjustment'].map({\"Unadjusted\": False, \"Seasonally adjusted\": True})\n",
        "#final_data.rename(columns={'Weather_key': 'Weather_keys'}, inplace=True)\n",
        "final_data.rename(columns={'Seasonal adjustment': 'Seasonally adjusted'}, inplace=True)\n",
        "\n",
        "# Sort by Date_key (and any other keys as secondary sorts if you wish)\n",
        "final_data = final_data.sort_values(by=['Date_key', 'Location_key'])\n",
        "\n",
        "# Convert 'Economy_key' to numeric, coercing errors, then to int64 where possible\n",
        "#final_data['Weather_key'] = pd.to_numeric(final_data['Weather_key'], errors='ignore').astype('Int64')\n",
        "final_data['Economy_key'] = pd.to_numeric(final_data['Economy_key'], errors='ignore').astype('Int64')\n",
        "# Replace NaN values in \"Weather_key\" column with pd.NA\n",
        "#final_data['Weather_key'] = final_data['Weather_key'].replace(np.nan, pd.NA)\n",
        "\n",
        "# Assuming df is your DataFrame and it has a column named \"Weather_key\"\n",
        "# First, ensure the column is of a type that supports pd.NA. If it's not, this step can be omitted.\n",
        "final_data['Economy_key'] = final_data['Economy_key'].astype('object')\n",
        "\n",
        "# Replace pd.NA with np.nan\n",
        "final_data['Economy_key'] = final_data['Economy_key'].fillna(np.nan)\n",
        "\n",
        "\n",
        "# Reset the index after sorting\n",
        "final_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the first few rows of the final sorted dataset\n",
        "#print(final_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkNgTDxKv9-U"
      },
      "source": [
        "View final data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "pmfwwuJL-Ins",
        "outputId": "0028b3fc-4965-462e-f10b-c428f17a7154"
      },
      "outputs": [],
      "source": [
        "final_data.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "I-B3Om3LQyjP",
        "outputId": "39756f4e-c26c-45bd-e5d9-24cf51ebcaa8"
      },
      "outputs": [],
      "source": [
        "final_data.tail(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auYJjxyiBRur"
      },
      "outputs": [],
      "source": [
        "# Save to file\n",
        "#final_data.to_csv(\"tourism_fact_table.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHSusdvzLbQb"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
