{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaEYKram3RHE"
      },
      "outputs": [],
      "source": [
        "# GOOGLE COLAB SETUP\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuWvw9_A_JDS"
      },
      "source": [
        "This is the beginning of the notebook.\n",
        "\n",
        "ADM4142-A Fundamentals of Data science <br>\n",
        "The goal of this notebook is to retrieve and stage the source datasets into the format used in the dimensional model for analysis.\n",
        "\n",
        "This notebook generates the Location_dimension of the weather/tourism/economy data frame.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2scVyd4JWuS"
      },
      "source": [
        "Rationale: <br>\n",
        "\n",
        "Location dimension:\n",
        "\n",
        "    Location_key (PK)\n",
        "    Date_key (FK)\n",
        "    location: string\n",
        "    population: int\n",
        "\n",
        "Location_key: integer enumeration of entries <br>\n",
        "Date_key: key associated to Jan. 1st of the year corresponding to each entry.\n",
        "(Only the year value is useful). <br>\n",
        "location: 5 values (Canada, Alberta, British Columbia, Ontario, Quebec) <br>\n",
        "population: annual population associated with the location and date above. <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofUAnz4SVsFV"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f8KJAfMV_JZQ",
        "outputId": "0353479c-ee7e-428a-c60f-7d9e91e4d68a"
      },
      "outputs": [],
      "source": [
        "# import datasets\n",
        "\n",
        "# URLs of the datasets\n",
        "urls = [\n",
        "    'https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/data/1710000501_databaseLoadingData-annualCanada-population.csv',\n",
        "    'https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/data/1710000501_databaseLoadingData-annualBritishColumbia-population.csv',\n",
        "    'https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/data/1710000501_databaseLoadingData-annualAlberta-population.csv',\n",
        "    'https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/data/1710000501_databaseLoadingData-annualOntario-population.csv',\n",
        "    'https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/data/1710000501_databaseLoadingData-annualQuebec-population.csv'\n",
        "]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Load, clean, and filter each dataset\n",
        "for url in urls:\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(url)\n",
        "\n",
        "    # Remove apostrophes from all cells\n",
        "    df = df.replace({\"\\\"\": \"\"}, regex=True)\n",
        "\n",
        "    # Filter rows based on conditions\n",
        "    df_filtered = df[(df['REF_DATE'] >= 1990) & (df['REF_DATE'] <= 2023) & (df['Age group'] == 'All ages')]\n",
        "\n",
        "    # Append the filtered DataFrame to the list\n",
        "    dataframes.append(df_filtered)\n",
        "\n",
        "# Combine all DataFrames into a single DataFrame\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "combined_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnhcDiHwaUr7"
      },
      "source": [
        "Now, generate the key mapping to map the REF_DATE value to the Jan. 1st date of the corresponding year in the dataset date.csv. (date.csv is the finished Date dimension from another notebook.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYTTiskiaK5R"
      },
      "outputs": [],
      "source": [
        "date_url = 'https://raw.githubusercontent.com/noobstang/cscsi4142-project-datasets/master/dimension/date.csv'\n",
        "date_df = pd.read_csv(date_url)\n",
        "\n",
        "# Filter for January 1st entries of each year\n",
        "jan_1st_entries = date_df[(date_df['month'] == 1) & (date_df['day'] == 1) & (date_df['year'].between(1990, 2023))]\n",
        "\n",
        "# Create the mapping of year to Date_key\n",
        "date_key_map = pd.Series(jan_1st_entries['Date_key'].values,index=jan_1st_entries['year']).to_dict()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai3zCRPwWaRq"
      },
      "source": [
        "Data transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip0p0RuvWbeB"
      },
      "outputs": [],
      "source": [
        "# Assume date_key_map is a dictionary mapping each year to its corresponding Date_key (FK) in 'date.csv'\n",
        "# Example: date_key_map = {1990: 1, 1991: 2, ..., 2023: 34}\n",
        "#date_key_map = {}  # This needs to be defined based on the 'date.csv' file\n",
        "\n",
        "# Mapping locations to a consistent format\n",
        "location_map = {\n",
        "    'Canada': 'Canada',\n",
        "    'British Columbia': 'British Columbia',\n",
        "    'Alberta': 'Alberta',\n",
        "    'Ontario': 'Ontario',\n",
        "    'Quebec': 'Quebec'\n",
        "}\n",
        "\n",
        "# Adding Location_key and Date_key to the DataFrame\n",
        "#combined_df['Location_key'] = combined_df.groupby('GEO').ngroup() + 1  # Integer enumeration for locations\n",
        "combined_df['Location_key'] = range(1, len(combined_df) + 1)\n",
        "combined_df['Date_key'] = combined_df['REF_DATE'].apply(lambda x: date_key_map.get(x))\n",
        "\n",
        "# Selecting and renaming columns to match the final dataset requirements\n",
        "final_df = combined_df[['Location_key', 'Date_key', 'GEO', 'VALUE']]\n",
        "final_df.columns = ['Location_key', 'Date_key', 'location', 'population']\n",
        "\n",
        "# Note: You may need to adjust the mapping and transformation logic based on the actual structure of 'date.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJbj95f4XGN2"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "S3ZSOoHMXF-k",
        "outputId": "6a5b9f05-0543-4f31-ee6e-3d9c69160e8b"
      },
      "outputs": [],
      "source": [
        "final_df.tail(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLZgTYwgWg6P"
      },
      "outputs": [],
      "source": [
        "# export to csv\n",
        "#final_df.to_csv('location.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
